# DS-4002-Project3
# ASL Alphabet Interpretation with a Convolutional Neural Network

This repository contains all files and documentation for our **DS 4002 Project 3**, which explores the use of a **Convolutional Neural Network (CNN)** to classify American Sign Language (ASL) hand signs from static images.  
Our goal is to evaluate whether a CNN can accurately identify ASL alphabet letters based on image input.

---

## Section 1: Software and Platform

**Programming Language:** Python (v3.10+)

**Primary Libraries Used:**
- `numpy`, `pandas` â€“ data handling and preprocessing  
- `matplotlib`, `seaborn` â€“ visualization  
- `tensorflow`, `keras` or `torch`, `torchvision` â€“ deep learning  
- `scikit-learn` â€“ model evaluation and metrics  
- `opencv-python` â€“ image preprocessing  
- `Pillow` â€“ image loading/resizing  
- `tqdm` â€“ progress tracking  
- `os`, `pathlib`, `glob` â€“ file management utilities  

**Platform(s) Used:**
- macOS Sonoma (development)
- Windows 11 (testing)
- Linux/Ubuntu (Google Colab & compatibility verification)

To install the required dependencies:
```bash
pip install -r requirements.txt

DS-4002-Project3/
â”‚
â”œâ”€â”€ ðŸ“„ README.md                  <- Orientation file (this document)
â”œâ”€â”€ ðŸ“„ LICENSE.md                 <- License information
â”œâ”€â”€ ðŸ“„ requirements.txt           <- Python dependencies
â”‚
â”œâ”€â”€ ðŸ“ data/                      <- Dataset (not uploaded to GitHub)
â”‚   â”œâ”€â”€ train/                    <- Training images by class
â”‚   â”œâ”€â”€ val/                      <- Validation images
â”‚   â””â”€â”€ test/                     <- Testing images
â”‚
â”œâ”€â”€ ðŸ“ src/                       <- Source code
â”‚   â”œâ”€â”€ train_model.py            <- Training script
â”‚   â”œâ”€â”€ eval_model.py             <- Evaluation script
â”‚   â”œâ”€â”€ preprocess_data.py        <- Preprocessing and augmentation
â”‚   â””â”€â”€ utils.py                  <- Helper functions
â”‚
â”œâ”€â”€ ðŸ“ notebooks/                 <- Jupyter notebooks
â”‚   â”œâ”€â”€ EDA.ipynb                 <- Exploratory Data Analysis
â”‚   â”œâ”€â”€ ModelTraining.ipynb       <- CNN development
â”‚   â””â”€â”€ ResultsSummary.ipynb      <- Evaluation and visualization
â”‚
â”œâ”€â”€ ðŸ“ output/                    <- Saved outputs
â”‚   â”œâ”€â”€ model_checkpoints/        <- Saved model weights (.h5 / .pt)
â”‚   â”œâ”€â”€ plots/                    <- Accuracy/loss plots, confusion matrices
â”‚   â””â”€â”€ metrics.json              <- Final metrics summary
â”‚
â””â”€â”€ ðŸ“ docs/                      <- Additional writeups (e.g., Analysis Plan)
    â”œâ”€â”€ AnalysisPlan.md
    â””â”€â”€ PresentationSlides.pptx

```

# **3. Instructions for Reproducing Our Results**

The following steps describe exactly how to reproduce all preprocessing, model training, and evaluation results generated in our project. These instructions assume the user is running the code contained in our repository without modification.

---

## **Step 1 â€” Clone the Repository**

Open a terminal and run:

```bash
git clone https://github.com/arotwell/DS-4002-Project3.git
cd DS-4002-Project3
```

This will download the full project folder, including scripts, data (or data-access instructions), and output files.

---

## **Step 2 â€” Install Required Packages**

Install the required Python packages (TensorFlow, NumPy, Matplotlib, scikit-learn, etc.) by running:

```bash
pip install -r requirements.txt
```

If running in Google Colab, upload the repository and run the same command.

---

## **Step 3 â€” Obtain and Prepare the Dataset**

1. Download the ASL image dataset from Mendeley Data:
   [https://data.mendeley.com/datasets/xs6mvhx6rh/1](https://data.mendeley.com/datasets/xs6mvhx6rh/1)
2. Unzip the dataset.
3. Place the extracted image folders into:

```
/DATA/raw/
```

4. Run the preprocessing script:

```bash
python SCRIPTS/1_preprocess_data.py
```

This script:

* Loads all image files
* Resizes them to the required CNN input size
* Normalizes pixel values
* Splits the dataset into training, validation, and test sets
* Saves final preprocessed arrays into:

```
/DATA/processed/
```

---

## **Step 4 â€” Create the Base ResNet Model**

Run:

```bash
python SCRIPTS/2_build_basemodel.py
```

This script:

* Imports the TensorFlow ResNet50 model pre-trained on ImageNet
* Removes its classification head
* Freezes all base layers
* Exports the base model for stacking custom layers

---

## **Step 5 â€” Build the Custom Classification Head**

Run:

```bash
python SCRIPTS/3_build_toplayers.py
```

This script attaches your custom top layers on top of ResNet, including:

* GlobalAveragePooling2D
* Dense layer(s)
* Dropout
* Final softmax classification layer

The script saves the combined model with base layers frozen.

---

## **Step 6 â€” Configure Callbacks**

Run:

```bash
python SCRIPTS/4_setup_callbacks.py
```

This sets up callbacks used during training:

* **EarlyStopping** (to prevent overfitting)
* **ReduceLROnPlateau** (to lower the learning rate when validation accuracy stalls)
* **ModelCheckpoint** (to save the best model)

---

## **Step 7 â€” Train Only the Top Layers (Base Frozen)**

Run:

```bash
python SCRIPTS/5_train_toplayers.py
```

This phase:

* Trains only the custom classification head
* Keeps all ResNet base layers frozen
* Uses a higher learning rate to stabilize the new layers
* Generates training and validation graphs in `/OUTPUT/`

---

## **Step 8 â€” Fine-Tune the Full Model**

Run:

```bash
python SCRIPTS/6_finetune_model.py
```

This script:

* Unfreezes the **top portion** of the ResNet base
* **Keeps all Batch Normalization layers frozen** (to avoid destabilizing the pretrained weights)
* Reduces the learning rate
* Continues training for fine-tuning
* Saves the best fine-tuned model (`best_model.h5`)

---

## **Step 9 â€” Evaluate the Final Model**

Run:

```bash
python SCRIPTS/7_evaluate_model.py
```

This will:

* Load the test set
* Compute accuracy, precision, recall, and confusion matrix
* Save the evaluation figures to:

```
/OUTPUT/
```

---

## **Step 10 â€” Generate Final Plots and Tables**

Run:

```bash
python SCRIPTS/8_generate_outputs.py
```

This generates:

* Training/validation accuracy curves
* Training/validation loss curves
* Confusion matrix
* Sample predictions
* EDA plots (q1.png, q2.png)

All output files appear in:

```
/OUTPUT/
```

